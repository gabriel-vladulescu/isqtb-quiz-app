{
    "examId": "sample-exam-c",
    "examName": "ISTQB CTFL Sample Exam C v1.7",
    "version": "1.7",
    "releaseDate": "2025-03-25",
    "syllabusVersion": "4.0",
    "isOfficial": true,
    "totalQuestions": 40,
    "totalPoints": 40,
    "passingScore": 26,
    "questions": [
        {
            "id": 1,
            "questionText": "Which of the following is a typical test objective?",
            "options": [
                {
                    "key": "a",
                    "text": "Validating that documented requirements are met"
                },
                {
                    "key": "b",
                    "text": "Causing failures and identifying defects"
                },
                {
                    "key": "c",
                    "text": "Initiating errors and identifying root causes"
                },
                {
                    "key": "d",
                    "text": "Verifying the test object meets user expectations"
                }
            ],
            "correctAnswer": "b",
            "selectType": "single",
            "explanation": {
                "a": "Validating that documented requirements are met is incorrect as validation is concerned with meeting user requirements and expectations, while verification is concerned with meeting specified requirements, so this would be correct if we replaced 'validating' with 'verifying'",
                "b": "Causing failures and identifying defects is probably the most common objective of dynamic testing",
                "c": "Initiating errors and identifying root causes is incorrect because testers do not initiate errors, they try to cause failures. Errors are typically made by developers (and cannot really be initiated) and result in defects, which testers attempt to identify either directly through static testing or indirectly through failures with dynamic testing. Identifying root causes is useful but is part of debugging, which is a separate activity from testing",
                "d": "Verifying the test object meets user expectations is incorrect as verification is concerned with checking specified (documented) requirements are met, while validation is concerned with meeting user requirements and expectations, so this would be correct if we replaced 'verifying' with 'validating'"
            },
            "learningObjective": "FL-1.1.1",
            "kLevel": "K1",
            "points": 1
        },
        {
            "id": 2,
            "questionText": "Which of the following statements BEST describes the difference between testing and debugging?",
            "options": [
                {
                    "key": "a",
                    "text": "Testing causes failures while debugging fixes failures"
                },
                {
                    "key": "b",
                    "text": "Testing is a negative activity while debugging is a positive activity"
                },
                {
                    "key": "c",
                    "text": "Testing determines that defects exist while debugging removes defects"
                },
                {
                    "key": "d",
                    "text": "Testing finds the cause of defects while debugging fixes the cause of defects"
                }
            ],
            "correctAnswer": "c",
            "selectType": "single",
            "explanation": {
                "a": "Dynamic testing does cause failures (from which defects can then be located and fixed). However, debugging is concerned with locating defects and fixing these defects. Therefore, debugging does not fix failures",
                "b": "Both testing and debugging contribute to improving the quality of the test object, so both should be considered positively. Debugging is generally considered to be a positive activity as it is fixing something. Dynamic testing does involve intentionally causing the test object to fail, which is why some people consider it a negative activity, but that is a very narrow view (and not one typically held by testers). Both positive and negative test cases are possible. Positive test cases check that the test object correctly performs what it is supposed to do, while negative testing checks that the test object does not do what it is not supposed to do",
                "c": "Testing determines that defects exist either directly through observation of the defect in reviews (or by a tool in static analysis), or indirectly by causing a failure in dynamic testing. Debugging is a separate activity from testing (normally performed by developers) and is concerned with locating defects (only for dynamic testing) and fixing the defects",
                "d": "The causes of defects are typically human errors. Testing finds defects either directly through static testing, or indirectly by causing failures in dynamic testing, and debugging fixes defects. So, testing does not find the cause of defects and debugging does not fix the causes of defects"
            },
            "learningObjective": "FL-1.1.2",
            "kLevel": "K2",
            "points": 1
        },
        {
            "id": 3,
            "questionText": "The ‘absence-of-defects fallacy’ is one of the principles of testing. Which of the following is an example of addressing this principle in practice?",
            "options": [
                {
                    "key": "a",
                    "text": "Explaining that it is not possible for testing to show the absence of defects"
                },
                {
                    "key": "b",
                    "text": "Supporting the end users to perform acceptance testing"
                },
                {
                    "key": "c",
                    "text": "Ensuring that no implementation defects remain in the delivered system"
                },
                {
                    "key": "d",
                    "text": "Modifying tests that cause no failures to ensure few defects remain"
                }
            ],
            "correctAnswer": "b",
            "selectType": "single",
            "explanation": {
                "a": "The 'testing shows the presence, not the absence of defects' principle explains that while testing can detect the existence of defects in the test object, it is not possible to demonstrate that there are no defects and, therefore, guarantee its correctness. Therefore, explaining that it is not possible for testing to show the absence of defects would partially address this principle, not the 'absence-of-defects' fallacy",
                "b": "By supporting the end user to perform acceptance testing it should be possible to validate that the system meets users' needs and expectations",
                "c": "It is not possible to ensure that no implementation defects remain in the delivered system as the 'testing shows the presence, not the absence of defects' principle explains that while testing can detect the existence of defects in the test object, it is not possible to demonstrate that there are no defects and, therefore, guarantee its correctness",
                "d": "Modifying tests that cause no failures to ensure few defects remain is one way to address the 'tests wear out' principle. This principle is concerned with the idea that repeating identical tests on unaltered code is unlikely to uncover novel defects and therefore, modifying tests may be essential. This will not validate that the system meets users' needs and expectations"
            },
            "learningObjective": "FL-1.3.1",
            "kLevel": "K2",
            "points": 1
        },
        {
            "id": 4,
            "questionText": "Which of the following test activities are MOST likely to involve the application of boundary value analysis and equivalence partitioning?",
            "options": [
                {
                    "key": "a",
                    "text": "Test implementation"
                },
                {
                    "key": "b",
                    "text": "Test design"
                },
                {
                    "key": "c",
                    "text": "Test execution"
                },
                {
                    "key": "d",
                    "text": "Test monitoring"
                },
                {
                    "key": "e",
                    "text": "Test analysis"
                }
            ],
            "correctAnswer": "b, e",
            "selectType": "multiple",
            "explanation": {
                "a": "Test implementation is not likely to involve the use of test techniques as it is mostly concerned with assembling test cases into test procedures, while test techniques create test cases",
                "b": "Test design is likely to involve the use of test techniques to create test cases from test conditions and coverage items",
                "c": "Test execution is not likely to involve the use of test techniques as it is mostly concerned with executing test procedures (and so test cases), while test techniques create test cases",
                "d": "Test monitoring is not likely to involve the use of test techniques. Test monitoring is mostly concerned with ongoing checks to ensure the plan is being followed, while test techniques create test cases",
                "e": "Test analysis is likely to involve the use of test techniques to identify test conditions"
            },
            "learningObjective": "FL-1.4.1",
            "kLevel": "K2",
            "points": 1
        },
        {
            "id": 5,
            "questionText": "Given the following testware: 1. Coverage items 2. Change requests 3. Test execution schedule 4. Prioritized test conditions And the following test activities A. Test analysis B. Test design C. Test implementation D. Test completion Which of the following BEST shows the testware produced by the activities?",
            "options": [
                {
                    "key": "a",
                    "text": "1B, 2D, 3C, 4A"
                },
                {
                    "key": "b",
                    "text": "1B, 2D, 3A, 4C"
                },
                {
                    "key": "c",
                    "text": "1D, 2C, 3A, 4B"
                },
                {
                    "key": "d",
                    "text": "1D, 2C, 3B, 4A"
                }
            ],
            "correctAnswer": "a",
            "selectType": "single",
            "explanation": {
                "a": "The correct match is: 1B (Coverage items are produced by test design), 2D (Change requests are produced by test completion), 3C (Test execution schedule is produced by test implementation), 4A (Prioritized test conditions are produced by test analysis)",
                "b": "Incorrect match",
                "c": "Incorrect match",
                "d": "Incorrect match"
            },
            "learningObjective": "FL-1.4.3",
            "kLevel": "K2",
            "points": 1
        },
        {
            "id": 6,
            "questionText": "Which of the following statements about the different testing roles is MOST likely to be CORRECT?",
            "options": [
                {
                    "key": "a",
                    "text": "In Agile software development, the test management role is the primary responsibility of the team, while the testing role is primarily the responsibility of a single individual from outside the team"
                },
                {
                    "key": "b",
                    "text": "The testing role is primarily responsible for test monitoring and test control, while the test management role is primarily responsible for test planning and test completion"
                },
                {
                    "key": "c",
                    "text": "In Agile software development, test management activities that span multiple teams are handled by a test manager outside the team, while some test management tasks are handled by the team itself"
                },
                {
                    "key": "d",
                    "text": "The test management role is primarily responsible for test analysis and test design, while the testing role is primarily responsible for test implementation and test execution"
                }
            ],
            "correctAnswer": "c",
            "selectType": "single",
            "explanation": {
                "a": "Although it is correct to say that in Agile software development, some of the test management tasks may be handled by the Agile team itself, the testing role is not primarily the responsibility of a single individual from outside the team. Instead the testing is more likely to be performed by various team members following the whole-team approach",
                "b": "The test management role primarily involves activities related to test planning, test monitoring and test control, and test completion. So, although this statement is partially correct, it is wrong to say that the testing role is primarily responsible for test monitoring and test control",
                "c": "In Agile software development, some of the test management tasks may be handled by the Agile team itself. However, for test activities that span multiple teams within an organization, test managers outside of the development team may perform these tasks",
                "d": "The test management role primarily involves activities related to test planning, test monitoring and test control, and test completion, while the testing role is primarily responsible for the technical and engineering aspects of testing, such as test analysis, test design, test implementation, and test execution. Thus the test management role is not normally responsible for test analysis and test design, although it is correct to say that the testing role is primarily responsible for test implementation and test execution"
            },
            "learningObjective": "FL-1.4.5",
            "kLevel": "K2",
            "points": 1
        },
        {
            "id": 7,
            "questionText": "Which of the following is an advantage of the whole-team approach?",
            "options": [
                {
                    "key": "a",
                    "text": "Teams with no testers"
                },
                {
                    "key": "b",
                    "text": "Improved team dynamics"
                },
                {
                    "key": "c",
                    "text": "Specialist team members"
                },
                {
                    "key": "d",
                    "text": "Larger team sizes"
                }
            ],
            "correctAnswer": "b",
            "selectType": "single",
            "explanation": {
                "a": "In the whole-team approach, testers play a vital role by sharing their testing expertise with the team and guiding product development. They collaborate with other team members to achieve the desired quality levels and work with business representatives to create acceptance tests. Testers also partner with developers to determine the optimal test strategy and test automation approaches",
                "b": "By leveraging the diverse skill sets of each team member most effectively, the whole-team approach fosters superior team dynamics, promotes robust communication and collaboration, and generates a synergistic effect that benefits the entire project",
                "c": "The whole-team approach allows any team member with the requisite skills and knowledge to undertake any task, thus specialist team members are not an advantage of this approach",
                "d": "There is no specific guidance on the optimum size of teams using the whole-team approach, and there is no suggestion that larger teams are better"
            },
            "learningObjective": "FL-1.5.2",
            "kLevel": "K1",
            "points": 1
        },
        {
            "id": 8,
            "questionText": "Which of the following statements about the independence of testing is CORRECT?",
            "options": [
                {
                    "key": "a",
                    "text": "Independent testers will find defects due to their different technical perspective from developers, but their independence may lead to an adversarial relationship with the developers"
                },
                {
                    "key": "b",
                    "text": "Developers’ familiarity with their own code means they only find a few defects in it, however their shared software background with testers means these defects would also be found by the testers"
                },
                {
                    "key": "c",
                    "text": "Independent testing requires testers who are outside the developer’s team and ideally from outside the organization, however these testers find it difficult to understand the application domain"
                },
                {
                    "key": "d",
                    "text": "Testers from outside the developer’s team are more independent than testers from within the team, but the testers from within the team are more likely to be blamed for delays in product release"
                }
            ],
            "correctAnswer": "a",
            "selectType": "single",
            "explanation": {
                "a": "The primary benefit of independence of testing is that testers are more likely to identify different types of failures and defects compared to developers, due to their varied backgrounds, technical viewpoints, and potential biases, including cognitive bias. However, the main disadvantage of independence of testing is that testers may become isolated from the development team, leading to communication problems, a lack of collaboration, and potentially an adversarial relationship, with testers being blamed for delays and bottlenecks in the release process",
                "b": "A developer's familiarity with the code does not mean that they rarely find defects in it, instead this familiarity means they can efficiently find many defects in their own code. And, rather than developers and testers having a shared background, developers having a different background to testers is normally cited as the reason that testers and developers find different kinds of defects",
                "c": "Testing can be performed at different levels of independence, ranging from no independence for the author to very high independence for testers from outside the organization. In most projects, multiple levels of independence are utilized, with developers performing component testing and component integration testing, the test team performing system testing and system integration testing, and business representatives performing acceptance testing. So, testers can be in the developer's team and do not need to come from outside the organization. Knowledge of the application domain will change from case to case and is not dependent on the level of independence",
                "d": "Testing can be performed at different levels of independence, ranging from no independence for the author to very high independence for testers from outside the organization, with testers from outside the developer's team generally more independent than testers from within the team. However, there is more reason to believe that testers from outside the team are likely to be more isolated from the developers and so are more likely to be blamed for delays in product release"
            },
            "learningObjective": "FL-1.5.3",
            "kLevel": "K2",
            "points": 1
        },
        {
            "id": 9,
            "questionText": "Which of the following is a good testing practice that applies to all software development lifecycles?",
            "options": [
                {
                    "key": "a",
                    "text": "For each test level, there is a corresponding development level"
                },
                {
                    "key": "b",
                    "text": "For each test objective, there is a corresponding development objective"
                },
                {
                    "key": "c",
                    "text": "For every test activity, there is a corresponding user activity"
                },
                {
                    "key": "d",
                    "text": "For every development activity, there is a corresponding test activity"
                }
            ],
            "correctAnswer": "d",
            "selectType": "single",
            "explanation": {
                "a": "Quality control applies to all development activities, meaning that every software development activity has a corresponding test activity. However, here we are attempting to equate test levels with development levels, and, although we know what is meant by 'test levels', there is no common understanding of the term 'development level'",
                "b": "Every software development activity has a corresponding test activity; however test objectives are quite different. For instance, there might be a test objective of ensuring that a test object adheres to a contractual requirement that a certain type of testing must be performed before delivery. In this case there is no reason for there to be a corresponding development objective",
                "c": "Quality control applies to all development activities, meaning that every software development activity has a corresponding test activity. However, the same symmetry does not apply to testing and user activities. For instance, for some systems it is difficult to even identify the end users. Also, some test activities are focused on developers (e.g., testing for ease of maintainability), which has no user aspect to it",
                "d": "Quality control applies to all development activities, meaning that every software development activity has a corresponding test activity"
            },
            "learningObjective": "FL-2.1.2",
            "kLevel": "K1",
            "points": 1
        },
        {
            "id": 10,
            "questionText": "Which of the following is an example of a test-first approach to development?",
            "options": [
                {
                    "key": "a",
                    "text": "Component Test-Driven Development"
                },
                {
                    "key": "b",
                    "text": "Integration Test-Driven Development"
                },
                {
                    "key": "c",
                    "text": "System Test-Driven Development"
                },
                {
                    "key": "d",
                    "text": "Acceptance Test-Driven Development"
                }
            ],
            "correctAnswer": "d",
            "selectType": "single",
            "explanation": {
                "a": "Component Test-Driven Development is not a correct example of a test-first approach to development",
                "b": "Integration Test-Driven Development is not a correct example of a test-first approach to development",
                "c": "System Test-Driven Development is not a correct example of a test-first approach to development",
                "d": "Acceptance Test-Driven Development (ATDD) is a well-known example of a test-first approach to development"
            },
            "learningObjective": "FL-2.1.3",
            "kLevel": "K1",
            "points": 1
        },
        {
            "id": 11,
            "questionText": "Which of the following provides the BEST description of shift-left?",
            "options": [
                {
                    "key": "a",
                    "text": "When agreed by the developers, manual activities on the left-hand side of the test process are automated to support the principle of ‘early testing saves time and money’"
                },
                {
                    "key": "b",
                    "text": "Where cost-effective, test activities are moved earlier in the software development lifecycle (SDLC) to reduce the total cost of quality by reducing the number of defects found later in the SDLC"
                },
                {
                    "key": "c",
                    "text": "When they have spare time available, testers are required to automate tests for regression testing, starting with component tests and component integration tests"
                },
                {
                    "key": "d",
                    "text": "When available, testers are trained to perform tasks early in the SDLC to allow more test activities to be automated later in the SDLC"
                }
            ],
            "correctAnswer": "b",
            "selectType": "single",
            "explanation": {
                "a": "Practices involved in shift left are aimed at implementing more test activities in the early phases of the software development life cycle (SDLC), portraying the SDLC as moving from left to right. There is no such thing as the left-hand side of the test process",
                "b": "Shift left emphasizes the importance of starting testing earlier in the SDLC. Implementing shift left testing necessitates additional training, and increased effort and costs during the early phases of the SDLC, nevertheless, overall savings should be higher",
                "c": "Although automated component tests and component integration tests for regression testing are generally valuable, the creation of these tests is normally the responsibility of the developers, and if a continuous integration/continuous delivery (CI/CD) approach is followed, then these tests will have been submitted with the code. In some situations the tester may automate tests for regression testing, and sometimes even for component tests and component integration tests, however this is not part of shift left which moves testing earlier in the SDLC",
                "d": "Training testers to perform tasks early in the SDLC would support a shift left approach by emphasizing the importance of starting testing earlier in the SDLC. However, automating more test activities to be performed later in the SDLC is not part of shift-left"
            },
            "learningObjective": "FL-2.1.5",
            "kLevel": "K2",
            "points": 1
        },
        {
            "id": 12,
            "questionText": "Which of the following is LEAST likely to occur as a result of a retrospective?",
            "options": [
                {
                    "key": "a",
                    "text": "The quality of future test objects improves by identifying improvements in development practices"
                },
                {
                    "key": "b",
                    "text": "Test efficiency improves by speeding up the configuration of test environments through automation"
                },
                {
                    "key": "c",
                    "text": "End users’ understanding of the development and test processes is improved"
                },
                {
                    "key": "d",
                    "text": "Automated test scripts are enhanced through feedback from developers"
                }
            ],
            "correctAnswer": "c",
            "selectType": "single",
            "explanation": {
                "a": "One of the purposes of retrospectives is to identify potential process improvements, which, if put into practice, should result in the quality of future outputs of the development process (test objects) being higher. So, this is likely to occur as a result of a retrospective",
                "b": "A benefit of retrospectives for testing includes increased test efficiency through process improvements. So, this is likely to occur as a result of a retrospective",
                "c": "Participants at retrospectives typically include testers, developers, architects, product owners, and business analysts, but end users are rarely invited or attend these meetings – and they are also unlikely to receive any reports from these meetings. So, it is very unlikely that they will learn and understand more about the development and test processes through retrospectives",
                "d": "A benefit of retrospectives for testing includes improved quality of testware (including automated test scripts) through joint reviews with developers. So, this is likely to occur as a result of a retrospective"
            },
            "learningObjective": "FL-2.1.6",
            "kLevel": "K2",
            "points": 1
        },
        {
            "id": 13,
            "questionText": "Which of the following test levels is MOST likely being performed if the testing is focused on validation and is not being performed by testers?",
            "options": [
                {
                    "key": "a",
                    "text": "Component testing"
                },
                {
                    "key": "b",
                    "text": "Component integration testing"
                },
                {
                    "key": "c",
                    "text": "System integration testing"
                },
                {
                    "key": "d",
                    "text": "Acceptance testing"
                }
            ],
            "correctAnswer": "d",
            "selectType": "single",
            "explanation": {
                "a": "Component testing (also called unit testing) involves testing individual components in isolation and is mostly verification against a specification, rather than validation against user needs. However, this testing is not normally performed by testers, as developers usually carry out this testing in their development environment",
                "b": "Component integration testing involves testing the interfaces and interactions between components and is mostly verification against a specification, rather than validation against user needs. However, this testing is not normally performed by testers, as developers usually carry out this testing",
                "c": "System integration testing examines the interfaces with other systems and external services and is mostly verification against a specification, rather than validation against user needs. This type of testing is also most often performed by testers",
                "d": "Acceptance testing focuses on validating that the system meets the user's business needs and is ready for deployment. Ideally, this testing is carried out by the end users"
            },
            "learningObjective": "FL-2.2.1",
            "kLevel": "K2",
            "points": 1
        },
        {
            "id": 14,
            "questionText": "The navigation system software has been updated due to it suggesting routes that break traffic laws, such as driving the wrong way down one-way streets. Which of the following BEST describes the testing that will be performed?",
            "options": [
                {
                    "key": "a",
                    "text": "Only confirmation testing"
                },
                {
                    "key": "b",
                    "text": "Confirmation testing then regression testing"
                },
                {
                    "key": "c",
                    "text": "Only regression testing"
                },
                {
                    "key": "d",
                    "text": "Regression testing then confirmation testing"
                }
            ],
            "correctAnswer": "b",
            "selectType": "single",
            "explanation": {
                "a": "Confirmation testing to check that the updates have resulted in a correct implementation is necessary, however, it would then be sensible to perform regression testing to ensure that no defects have been introduced or uncovered in unchanged areas of the system",
                "b": "Confirmation testing will check that the updates have resulted in a correct implementation, and then regression testing will be used to ensure that no defects have been introduced or uncovered in unchanged areas of the system",
                "c": "Regression testing should be used to ensure that no defects have been introduced or uncovered in unchanged areas of the system when the update was made, however it is also necessary to perform confirmation testing that will check that the updates have resulted in a correct implementation",
                "d": "Confirmation testing will check that the updates have resulted in a correct implementation, and regression testing will be used to ensure that no defects have been introduced or uncovered in unchanged areas of the system. However, when performed (i.e., when an update needs to be tested), confirmation testing precedes regression testing"
            },
            "learningObjective": "FL-2.2.3",
            "kLevel": "K2",
            "points": 1
        },
        {
            "id": 15,
            "questionText": "Given the following example defects: i. Two different parts of the design specification disagree due to the complexity of the design ii. A response time is too long and so makes users lose patience iii. A path in the code cannot be reached during execution iv. A variable is declared but never subsequently used in the program v. The amount of memory needed by the program to generate a report is too high Which of the following BEST identifies example defects that could be found by static testing (rather than dynamic testing)?",
            "options": [
                {
                    "key": "a",
                    "text": "ii, v"
                },
                {
                    "key": "b",
                    "text": "iii, v"
                },
                {
                    "key": "c",
                    "text": "i, ii, iv"
                },
                {
                    "key": "d",
                    "text": "i, iii, iv"
                }
            ],
            "correctAnswer": "d",
            "selectType": "single",
            "explanation": {
                "a": "Examples ii and v are performance-related defects that can only be detected by dynamic testing",
                "b": "Examples iii and v can be found by static testing, but example v is a performance defect that requires dynamic testing",
                "c": "Examples i and iv can be found by static testing, but example ii is a performance defect that requires dynamic testing",
                "d": "Examples i, iii, and iv can all be found by static testing. Example i is a specification defect (inconsistencies), example iii is a coding defect (unreachable code), and example iv is a coding defect (undeclared variables)"
            },
            "learningObjective": "FL-3.1.3",
            "kLevel": "K2",
            "points": 1
        },
        {
            "id": 16,
            "questionText": "Which of the following is a benefit of early and frequent stakeholder feedback?",
            "options": [
                {
                    "key": "a",
                    "text": "Changes to requirements are understood and implemented earlier"
                },
                {
                    "key": "b",
                    "text": "It ensures business stakeholders understand user requirements"
                },
                {
                    "key": "c",
                    "text": "It allows product owners to change their requirements as often as they want"
                },
                {
                    "key": "d",
                    "text": "End users are told which requirements will not be implemented prior to release"
                }
            ],
            "correctAnswer": "a",
            "selectType": "single",
            "explanation": {
                "a": "Obtaining feedback from stakeholders early and often in the software development process can be highly beneficial. It facilitates early communication of potential quality issues, can prevent misunderstandings about requirements, and ensures that any changes in stakeholder requirements are understood and implemented sooner",
                "b": "The feedback is from stakeholders, so providing feedback is unlikely to improve their understanding of their own user requirements",
                "c": "Obtaining feedback from stakeholders early and often in the software development process can be highly beneficial. It facilitates early communication of potential quality issues, can prevent misunderstandings about requirements, and ensures that any changes in stakeholder requirements are understood and implemented sooner. However, because changes in requirements can be understood and implemented sooner, it does not mean that unlimited changes to requirements are encouraged",
                "d": "The feedback is from stakeholders and does not cover communication to them. Communications with end users could include telling them about which requirements will not be implemented prior to release, but ideally this should not happen at all"
            },
            "learningObjective": "FL-3.2.1",
            "kLevel": "K1",
            "points": 1
        },
        {
            "id": 17,
            "questionText": "Given the following review types: 1. Technical review 2. Informal review 3. Inspection 4. Walkthrough And the following descriptions: A. Includes objectives such as gaining consensus, generating new ideas, and motivating authors to improve B. Includes objectives such as educating reviewers, gaining consensus, generating new ideas and detecting potential defects C. The main objective is detecting potential defects and it requires metrics collection to support process improvement D. The main objective is detecting potential defects and it generates no formal documented output Which of the following BEST matches the review types and the descriptions?",
            "options": [
                {
                    "key": "a",
                    "text": "1A, 2B, 3C, 4D"
                },
                {
                    "key": "b",
                    "text": "1A, 2D, 3C, 4B"
                },
                {
                    "key": "c",
                    "text": "1B, 2C, 3D, 4A"
                },
                {
                    "key": "d",
                    "text": "1C, 2D, 3A, 4B"
                }
            ],
            "correctAnswer": "b",
            "selectType": "single",
            "explanation": {
                "a": "Incorrect match. Technical review objectives include gaining consensus, making decisions, generating new ideas, and motivating authors, but these are not unique to technical reviews",
                "b": "Correct match: 1A (Technical review - gaining consensus, generating new ideas, motivating authors), 2D (Informal review - detecting anomalies with no formal output), 3C (Inspection - detecting anomalies with metrics collection), 4B (Walkthrough - educating reviewers, gaining consensus, generating new ideas, detecting anomalies)",
                "c": "Incorrect match",
                "d": "Incorrect match"
            },
            "learningObjective": "FL-3.2.4",
            "kLevel": "K2",
            "points": 1
        },
        {
            "id": 18,
            "questionText": "Which of the following is a factor that contributes to a successful review?",
            "options": [
                {
                    "key": "a",
                    "text": "Ensure management participate as reviewers"
                },
                {
                    "key": "b",
                    "text": "Split large work products into smaller parts"
                },
                {
                    "key": "c",
                    "text": "Set reviewer evaluation as an objective"
                },
                {
                    "key": "d",
                    "text": "Plan to cover one document per review"
                }
            ],
            "correctAnswer": "b",
            "selectType": "single",
            "explanation": {
                "a": "To ensure successful reviews, it is important to secure management's support for the review process. However that does not mean that they should participate as reviewers",
                "b": "To ensure successful reviews, it's important to break the work product into parts that are small enough to be reviewed in a reasonable timescale to prevent reviewers from losing focus during individual reviews or review meetings",
                "c": "To ensure successful reviews, it's important to clearly define objectives and measurable exit criteria, without evaluating participants",
                "d": "To ensure successful reviews, it's important to break down the review into smaller chunks to prevent reviewers from losing focus during individual reviews or review meetings. So you should not plan to cover one document per review"
            },
            "learningObjective": "FL-3.2.5",
            "kLevel": "K1",
            "points": 1
        },
        {
            "id": 19,
            "questionText": "What is the MAIN difference between black-box test techniques and experience-based test techniques?",
            "options": [
                {
                    "key": "a",
                    "text": "The test object"
                },
                {
                    "key": "b",
                    "text": "The test level at which the test technique is used"
                },
                {
                    "key": "c",
                    "text": "The test basis"
                },
                {
                    "key": "d",
                    "text": "The software development lifecycle (SDLC) in which the test technique can be used"
                }
            ],
            "correctAnswer": "c",
            "selectType": "single",
            "explanation": {
                "a": "In most cases both black-box test techniques and experience-based test techniques can be used for the same test objects",
                "b": "Both black-box test techniques and experience-based test techniques can be used at all test levels",
                "c": "Black-box test techniques (also known as specification-based techniques) are based on an analysis of the specified behavior of the test object without reference to its internal structure. So, the test basis is usually a specification. Experience-based test techniques effectively use the knowledge and experience of testers for the design and implementation of test cases. This means that the tester, when designing tests, may not use the specification at all",
                "d": "Experience-based test techniques can detect defects that may be missed using black-box (and white-box) test techniques. Hence, experience-based test techniques are complementary to black-box test techniques and white-box test techniques and both black-box test techniques and experience-based test techniques can be used in all SDLCs"
            },
            "learningObjective": "FL-4.1.1",
            "kLevel": "K2",
            "points": 1
        },
        {
            "id": 20,
            "questionText": "You are testing a PIN validator, which accepts valid PINs and rejects invalid PINs. A PIN is a sequence of digits. A PIN is valid if it consists of four digits, which are not all the same digit. You have identified the following valid equivalence partitions: Variable: PIN code length • The partition “length correct” • The partition “length incorrect” Variable: Number of different digits - four-digit PINs - PINs with length other than 4 • The partition “number of different digits correct” - PINs with at least two different digits • The partition “number of different digits incorrect” - PINs with all digits being the same Which of the following is the BEST set of input test data to cover the identified equivalence partitions?",
            "options": [
                {
                    "key": "a",
                    "text": "12, 1111, 1234, 12345"
                },
                {
                    "key": "b",
                    "text": "1, 123, 1111, 1234"
                },
                {
                    "key": "c",
                    "text": "11, 12, 1111, 12345"
                },
                {
                    "key": "d",
                    "text": "123, 1222, 12345"
                }
            ],
            "correctAnswer": "a",
            "selectType": "single",
            "explanation": {
                "a": "Value '12' covers 'length incorrect, too few digits', value '1111' covers 'length correct' and 'number of different digits incorrect', value '1234' covers 'length correct' and 'number of different digits correct', value '12345' covers 'length incorrect, too many digits'",
                "b": "All partitions are covered, however it only covers the lower side of 'length incorrect'",
                "c": "There are no values covering 'correct PIN'",
                "d": "There are no values covering 'number of different digits'"
            },
            "learningObjective": "FL-4.2.1",
            "kLevel": "K3",
            "points": 1
        },
        {
            "id": 21,
            "questionText": "A developer was asked to implement the following business rule: INPUT: value (integer number) IF (value ≤ 100 OR value ≥ 200) THEN write “value incorrect” ELSE write “value OK” You design the test cases using 2-value boundary value analysis. Which of the following sets of test inputs achieves the greatest coverage?",
            "options": [
                {
                    "key": "a",
                    "text": "100, 150, 200, 201"
                },
                {
                    "key": "b",
                    "text": "99, 100, 200, 201"
                },
                {
                    "key": "c",
                    "text": "98, 99, 100, 101"
                },
                {
                    "key": "d",
                    "text": "101, 150, 199, 200"
                }
            ],
            "correctAnswer": "d",
            "selectType": "single",
            "explanation": {
                "a": "Only 100 and 200 are valid coverage items for 2-value BVA, so we achieve 50% coverage",
                "b": "Only 100 and 200 are valid coverage items for 2-value BVA, so we achieve 50% coverage",
                "c": "Only 100 and 101 are valid coverage items for 2-value BVA, so we achieve 50% coverage",
                "d": "101, 199 and 200 are valid coverage items for 2-value BVA, so we achieve 75% coverage. The equivalence partitions are: {..., 99, 100}, {101, 102, ..., 198, 199}, {200, 201, ...}. Thus, there are 4 boundary values: 100, 101, 199 and 200"
            },
            "learningObjective": "FL-4.2.2",
            "kLevel": "K3",
            "points": 1
        },
        {
            "id": 22,
            "questionText": "You are working on a project to develop a system to analyze driving test results. You have been asked to design test cases based on the following decision table. R1 R2 R3 C1: First attempt at the exam? C2: Theoretical exam passed? - - F C3: Practical exam passed? T F - T - F Issue a driving license? Request additional driving lessons? X Request to take the exam again? X X What test data will show that there are contradictory rules in the decision table?",
            "options": [
                {
                    "key": "a",
                    "text": "C1 = T, C2 = T, C3 = F"
                },
                {
                    "key": "b",
                    "text": "C1 = T, C2 = F, C3 = T"
                },
                {
                    "key": "c",
                    "text": "C1 = T, C2 = T, C3 = T and C1 = F, C2 = T, C3 = T"
                },
                {
                    "key": "d",
                    "text": "C1 = F, C2 = F, C3 = F"
                }
            ],
            "correctAnswer": "d",
            "selectType": "single",
            "explanation": {
                "a": "The combination (T, T, F) does not match any rule. This is an example of omission, not a contradiction",
                "b": "The combination (T, F, T) matches only one column, R2, so there is no contradiction",
                "c": "Both combinations (T, T, T) and (F, T, T) match only one column, R1, so there is no contradiction",
                "d": "The combination (F, F, F) matches both R2 and R3, but R2 and R3 have different actions, so this shows a contradiction between R2 and R3"
            },
            "learningObjective": "FL-4.2.3",
            "kLevel": "K3",
            "points": 1
        },
        {
            "id": 23,
            "questionText": "You are designing test cases based on the following state transition diagram: What is the MINIMUM number of test cases required to achieve 100% valid transitions coverage?",
            "options": [
                {
                    "key": "a",
                    "text": "3"
                },
                {
                    "key": "b",
                    "text": "2"
                },
                {
                    "key": "c",
                    "text": "5"
                },
                {
                    "key": "d",
                    "text": "6"
                }
            ],
            "correctAnswer": "a",
            "selectType": "single",
            "explanation": {
                "a": "The minimum number of test cases required is 3. The transitions 'REQUESTING -> CONFIRMED', 'WAITING LIST -> CONFIRMED', and 'WAITING LIST -> END' cannot appear in the same test case. All other transitions can appear in combination with one or more of these three transitions, so we need a minimum of three test cases",
                "b": "Incorrect. Minimum is 3 test cases",
                "c": "Incorrect. Minimum is 3 test cases",
                "d": "Incorrect. Minimum is 3 test cases"
            },
            "learningObjective": "FL-4.2.4",
            "kLevel": "K3",
            "points": 1
        },
        {
            "id": 24,
            "questionText": "You want to apply branch testing to the code represented by the following control flow graph. How many coverage items do you need to test?",
            "options": [
                {
                    "key": "a",
                    "text": "2"
                },
                {
                    "key": "b",
                    "text": "4"
                },
                {
                    "key": "c",
                    "text": "8"
                },
                {
                    "key": "d",
                    "text": "7"
                }
            ],
            "correctAnswer": "c",
            "selectType": "single",
            "explanation": {
                "a": "Incorrect. In branch testing the coverage items are branches, which are represented by the edges of a control flow graph",
                "b": "Incorrect. In branch testing the coverage items are branches, which are represented by the edges of a control flow graph",
                "c": "In branch testing the coverage items are branches, which are represented by the edges of a control flow graph. There are 8 edges in the control flow graph",
                "d": "Incorrect. In branch testing the coverage items are branches, which are represented by the edges of a control flow graph"
            },
            "learningObjective": "FL-4.3.2",
            "kLevel": "K2",
            "points": 1
        },
        {
            "id": 25,
            "questionText": "How can white-box testing be useful in support of black-box testing?",
            "options": [
                {
                    "key": "a",
                    "text": "White-box coverage measures can help testers evaluate black-box tests in terms of the code coverage achieved by these black-box tests"
                },
                {
                    "key": "b",
                    "text": "White-box coverage analysis can help testers identify unreachable fragments of the source code"
                },
                {
                    "key": "c",
                    "text": "Branch testing subsumes black-box test techniques, so achieving full branch coverage guarantees achieving full coverage of any black-box technique"
                },
                {
                    "key": "d",
                    "text": "White-box test techniques can provide coverage items for black-box techniques"
                }
            ],
            "correctAnswer": "a",
            "selectType": "single",
            "explanation": {
                "a": "Performing only black-box testing does not provide a measure of actual code coverage. White-box coverage measures provide an objective measurement of coverage and provide the necessary information to allow additional tests to be generated to increase this coverage, and subsequently increase confidence in the code",
                "b": "This statement is correct, but it has nothing to do with black-box testing",
                "c": "In general there are no relationships between white-box test techniques and black-box test techniques",
                "d": "White-box test techniques are used to design tests based on the test object itself, while black-box test techniques are used to design tests based on the specification. Therefore, there is no relation between coverage items derived from these two types of test techniques"
            },
            "learningObjective": "FL-4.3.3",
            "kLevel": "K2",
            "points": 1
        },
        {
            "id": 26,
            "questionText": "Consider the following list: \n• Correct input not accepted \n• Incorrect input accepted \n• Wrong output format \n• Division by zero What test technique is MOST PROBABLY used by the tester who uses this list when performing testing?",
            "options": [
                {
                    "key": "a",
                    "text": "Exploratory testing"
                },
                {
                    "key": "b",
                    "text": "Fault attack"
                },
                {
                    "key": "c",
                    "text": "Checklist-based testing"
                },
                {
                    "key": "d",
                    "text": "Boundary value analysis"
                }
            ],
            "correctAnswer": "b",
            "selectType": "single",
            "explanation": {
                "a": "Exploratory testing uses test charters, not a list of possible defects/failures. Although exploratory testing can incorporate the use of other test techniques, in this case a fault attack is the most likely option",
                "b": "This is a list of possible failures. Fault attacks are a methodical approach to the implementation of error guessing and require the tester to create or acquire a list of possible errors, defects and failures, and to design tests that will identify defects associated with the errors, expose the defects, or cause the failures",
                "c": "The tester is using a checklist of items to support their testing. Both error guessing and checklist-based testing use such lists, however, the list here is of possible failures, not test conditions, and so the MOST PROBABLE test technique is fault attack, which focuses on errors, defects and failures",
                "d": "BVA is based on an analysis of boundary values of equivalence partitions. The above list does not mention equivalence partitions or their boundaries"
            },
            "learningObjective": "FL-4.4.1",
            "kLevel": "K2",
            "points": 1
        },
        {
            "id": 27,
            "questionText": "Which of the following BEST describes how using checklist-based testing can result in increased coverage?",
            "options": [
                {
                    "key": "a",
                    "text": "Checklist items can be defined at a sufficiently low level of detail, so the tester can implement and execute detailed test cases based on these items"
                },
                {
                    "key": "b",
                    "text": "Checklists can be automated, so each time an automated test execution covers the checklist items, it results in additional coverage"
                },
                {
                    "key": "c",
                    "text": "Each checklist item should be tested separately and independently, so the elements cover different areas of the software"
                },
                {
                    "key": "d",
                    "text": "Two testers designing and executing tests based on the same high-level checklist items will typically perform the testing in slightly different ways"
                }
            ],
            "correctAnswer": "d",
            "selectType": "single",
            "explanation": {
                "a": "Although it is true that the tester can implement and execute detailed test cases based on the checklist, it does not explain how this would result in increased coverage",
                "b": "Checklist items should not be automated. But even if they are, the automated test scripts always execute the tests in the same way, which usually does not result in increased coverage",
                "c": "It is true that each checklist item should be tested separately and independently. But this impacts the test execution order and does not impact the achieved coverage, and so does not result in increased coverage",
                "d": "If the checklists are high-level, some variability in the actual testing is likely to occur, resulting in potentially greater coverage but less repeatability. If two testers follow a checklist of high-level items, each of them may use different test data, test steps, etc. This way, one tester will probably cover some areas not covered by the other tester and this will result in increased coverage"
            },
            "learningObjective": "FL-4.4.3",
            "kLevel": "K2",
            "points": 1
        },
        {
            "id": 28,
            "questionText": "Which of the following provides the BEST example of a scenario-oriented acceptance criterion?",
            "options": [
                {
                    "key": "a",
                    "text": "The application must allow users to delete their account and all associated data upon request"
                },
                {
                    "key": "b",
                    "text": "When a customer adds an item to their cart and proceeds to checkout, they should be prompted to log in or create an account if they haven’t already done so"
                },
                {
                    "key": "c",
                    "text": "IF (contain(product(23).Name, cart.products())) THEN return FALSE"
                },
                {
                    "key": "d",
                    "text": "The website must comply with the ICT Accessibility 508 Standards and ensure that all content is accessible to users with disabilities"
                }
            ],
            "correctAnswer": "b",
            "selectType": "single",
            "explanation": {
                "a": "This acceptance criterion describes what rules or regulations the system must adhere to (in this case, the right to be forgotten). This is an example of a rule-oriented acceptance criterion",
                "b": "This acceptance criterion describes an example scenario that must be realized by the system. This is an example of a scenario-oriented acceptance criterion",
                "c": "This sentence looks more like a line of code that implements some business rule. Acceptance criteria should be written in collaboration with business representatives, and therefore should be written in language they understand. This sentence will most likely be unintelligible to these stakeholders",
                "d": "This acceptance criterion describes what rules or regulations the system must adhere to and how compliance will be ensured. Therefore, this is an example of a rule-oriented acceptance criterion, not a scenario-based acceptance criterion"
            },
            "learningObjective": "FL-4.5.2",
            "kLevel": "K2",
            "points": 1
        },
        {
            "id": 29,
            "questionText": "You are using acceptance test-driven development and designing test cases based on the following user story: As a Regular or Special user, I want to be able to use my electronic floor card, to access specific floors. Acceptance Criteria: AC1: Regular users have access to floors 1 to 3 AC2: Floor 4 is only accessible to Special users AC3: Special users have all the access rights of Regular users Which test case is the MOST reasonable one to test AC3?",
            "options": [
                {
                    "key": "a",
                    "text": "Check that a Regular user can access floors 1 and 3"
                },
                {
                    "key": "b",
                    "text": "Check that a Regular user cannot access floor 4"
                },
                {
                    "key": "c",
                    "text": "Check that a Special user can access floor 5"
                },
                {
                    "key": "d",
                    "text": "Check that a Special user can access floors 1, 2 and 3"
                }
            ],
            "correctAnswer": "d",
            "selectType": "single",
            "explanation": {
                "a": "We want to check that Special users have the rights of Regular users, so we need to test access rights for a Special user, not for a Regular user",
                "b": "We want to check that Special users have the rights of Regular users, so we need to test access rights for a Special user, not for a Regular user",
                "c": "There is no floor 5 described in the acceptance criteria. The test cases should not extend the scope of the user story. But even if we would like to perform negative testing, this test is not directly related to AC3",
                "d": "This is the way we can check if a Special user can access floors which are accessible to a Regular user"
            },
            "learningObjective": "FL-4.5.3",
            "kLevel": "K3",
            "points": 1
        },
        {
            "id": 30,
            "questionText": "Which of the following is NOT a purpose of a test plan?",
            "options": [
                {
                    "key": "a",
                    "text": "To define test data and expected results for component tests and component integration tests"
                },
                {
                    "key": "b",
                    "text": "To define as exit criteria from the component test level that “100% statement coverage and 100% branch coverage must be achieved”"
                },
                {
                    "key": "c",
                    "text": "To describe what fields the test progress report shall contain and what should be the form of this report"
                },
                {
                    "key": "d",
                    "text": "To explain why system integration testing will be excluded from testing, although the test strategy requires this test level"
                }
            ],
            "correctAnswer": "a",
            "selectType": "single",
            "explanation": {
                "a": "The test plan may include test data requirements (as part of the test approach), but not the detailed test data for test cases. Test data is part of the test cases, not the test plan. Also, it is usually impossible to define such data when the test plan is created, because it is not exactly known what the components will look like",
                "b": "One of the purposes of a test plan is to help ensure that test activities will meet the established criteria, by including entry criteria and exit criteria. The code coverage criteria are an example of such criteria for the component test level",
                "c": "Documentation templates are typical content of a test plan. This helps to facilitate communication between the stakeholders by defining a standard way of communicating or reporting",
                "d": "One of the purposes of a test plan is to demonstrate that testing will adhere to the existing test policy and test strategy, or to explain why the testing will deviate from them. This is an example of explaining the deviation, regarding the test levels that will be (or will not be) followed"
            },
            "learningObjective": "FL-5.1.1",
            "kLevel": "K2",
            "points": 1
        },
        {
            "id": 31,
            "questionText": "At the beginning of each iteration, the team estimates the amount of work (in person-days) they will need to complete during the iteration. Let E(n) be the estimated amount of work for iteration n, and let A(n) be the actual amount of work done in iteration n. From the third iteration, the team uses the following estimation model based on extrapolation: E(n) = (3*A(n-1) + A(n-2)) / 4 The graph shows the estimated and actual amount of work for the first four iterations. Estimated and actual effort (in person-days) 13 12 11 10 0 1 2 3 4 5 6 7 8 9 Iteration #1 Iteration #2 Estimated What is the estimated amount of work for iteration #5?",
            "options": [
                {
                    "key": "a",
                    "text": "10.5 person-days"
                },
                {
                    "key": "b",
                    "text": "8.25 person-days"
                },
                {
                    "key": "c",
                    "text": "6.5 person-days"
                },
                {
                    "key": "d",
                    "text": "9.4 person-days"
                }
            ],
            "correctAnswer": "c",
            "selectType": "single",
            "explanation": {
                "a": "Incorrect. E(5) = (3*A(4) + A(3)) / 4 = (3*6+8) / 4 = 26 / 4 = 6.5 person-days",
                "b": "Incorrect. E(5) = (3*A(4) + A(3)) / 4 = (3*6+8) / 4 = 26 / 4 = 6.5 person-days",
                "c": "From the graph: A(4)=6 and A(3)=8. From the formula: E(5) = (3*A(4) + A(3)) / 4 = (3*6+8) / 4 = 26 / 4 = 6.5 person-days",
                "d": "Incorrect. E(5) = (3*A(4) + A(3)) / 4 = (3*6+8) / 4 = 26 / 4 = 6.5 person-days"
            },
            "learningObjective": "FL-5.1.4",
            "kLevel": "K3",
            "points": 1
        },
        {
            "id": 32,
            "questionText": "You are preparing a test execution schedule for executing seven test cases TC 1 to TC 7. The following figure includes the priorities of these test cases (1=highest priority, 3 = lowest priority). The figure also shows the dependencies between test cases using arrows. For instance, the arrow from TC 4 to TC 5 means that TC 5 can only be executed if TC 4 was previously executed. Which test case should be executed sixth?",
            "options": [
                {
                    "key": "a",
                    "text": "TC 3"
                },
                {
                    "key": "b",
                    "text": "TC 5"
                },
                {
                    "key": "c",
                    "text": "TC 6"
                },
                {
                    "key": "d",
                    "text": "TC 2"
                }
            ],
            "correctAnswer": "a",
            "selectType": "single",
            "explanation": {
                "a": "The schedule considering both priorities and dependencies is: TC 4 – TC 7 – TC 1 – TC 2 – TC 5 – TC 3 – TC 6. The sixth test case will be TC 3",
                "b": "Incorrect. The sixth test case should be TC 3",
                "c": "Incorrect. The sixth test case should be TC 3",
                "d": "Incorrect. The sixth test case should be TC 3"
            },
            "learningObjective": "FL-5.1.5",
            "kLevel": "K3",
            "points": 1
        },
        {
            "id": 33,
            "questionText": "What does the test pyramid model show?",
            "options": [
                {
                    "key": "a",
                    "text": "That tests may have different priorities"
                },
                {
                    "key": "b",
                    "text": "That tests may have different granularity"
                },
                {
                    "key": "c",
                    "text": "That tests may require different coverage criteria"
                },
                {
                    "key": "d",
                    "text": "That tests may depend on other tests"
                }
            ],
            "correctAnswer": "b",
            "selectType": "single",
            "explanation": {
                "a": "The test pyramid model does not provide information about test priorities",
                "b": "The test pyramid model shows that different tests have different levels of granularity",
                "c": "The test pyramid model is independent of coverage criteria",
                "d": "Test pyramid model does not show any relations between different tests"
            },
            "learningObjective": "FL-5.1.6",
            "kLevel": "K1",
            "points": 1
        },
        {
            "id": 34,
            "questionText": "What is the relationship between the testing quadrants, test levels and test types?",
            "options": [
                {
                    "key": "a",
                    "text": "Testing quadrants represent particular combinations of test levels and test types, defining their location in the software development lifecycle"
                },
                {
                    "key": "b",
                    "text": "Testing quadrants describe the degree of granularity of individual test types performed at each test level"
                },
                {
                    "key": "c",
                    "text": "Testing quadrants assign the test types that can be performed to the test levels"
                },
                {
                    "key": "d",
                    "text": "Testing quadrants group test levels and test types by several criteria such as targeting specific stakeholders"
                }
            ],
            "correctAnswer": "d",
            "selectType": "single",
            "explanation": {
                "a": "Testing quadrants group test levels and test types separately according to several criteria. They do not represent any combinations of test levels and test types and they are not related to any location within a software development lifecycle. Both test levels and test types are treated separately in the testing quadrants model",
                "b": "Testing quadrants group test levels and test types according to several criteria. They do not describe the degree of granularity of individual test types performed at each test level. Such a model, regarding the test levels, is called the test pyramid",
                "c": "The statement is wrong, because in general any test type can be performed at any test level",
                "d": "The testing quadrants group test levels, test types, test activities, test techniques and work products in Agile software development. In this model, tests can be business facing or technology facing. Tests can support the team (i.e., guide the development) or critique the product (i.e., measure its behavior against expectations). The combination of these two viewpoints determines the four quadrants"
            },
            "learningObjective": "FL-5.1.7",
            "kLevel": "K2",
            "points": 1
        },
        {
            "id": 35,
            "questionText": "Which of the following is an example of how product risk analysis may influence the thoroughness and scope of testing?",
            "options": [
                {
                    "key": "a",
                    "text": "Continuous risk monitoring allows us to identify an emerging risk as soon as possible"
                },
                {
                    "key": "b",
                    "text": "Risk identification allows us to implement risk mitigation activities and reduce the risk level"
                },
                {
                    "key": "c",
                    "text": "The assessed risk level helps us to select the rigor of testing"
                },
                {
                    "key": "d",
                    "text": "Risk analysis allows us to derive coverage items"
                }
            ],
            "correctAnswer": "c",
            "selectType": "single",
            "explanation": {
                "a": "Risk monitoring is part of risk control, not risk analysis",
                "b": "Risk identification itself does not allow us to implement risk mitigation activities. The mitigating actions are defined during the risk control phase",
                "c": "This is an example of how risk analysis influences the thoroughness and scope of testing",
                "d": "Coverage items are derived using test techniques, not through risk analysis"
            },
            "learningObjective": "FL-5.2.3",
            "kLevel": "K2",
            "points": 1
        },
        {
            "id": 36,
            "questionText": "Which of the following activities in the test process makes the MOST use of test progress reports?",
            "options": [
                {
                    "key": "a",
                    "text": "Test design"
                },
                {
                    "key": "b",
                    "text": "Test completion"
                },
                {
                    "key": "c",
                    "text": "Test analysis"
                },
                {
                    "key": "d",
                    "text": "Test planning"
                }
            ],
            "correctAnswer": "b",
            "selectType": "single",
            "explanation": {
                "a": "Test progress reports are mostly used during test monitoring and test control, and test completion, not during test design",
                "b": "A test completion report is prepared during test completion, when a project, test level, or test type is complete and when, ideally, its exit criteria have been met. This report uses information from test progress reports and other data",
                "c": "Test progress reports are mostly used during test monitoring and test control, and test completion, not during test analysis",
                "d": "Test progress reports are most used during test monitoring and test control, and test completion, not during test planning"
            },
            "learningObjective": "FL-5.3.2",
            "kLevel": "K2",
            "points": 1
        },
        {
            "id": 37,
            "questionText": "Which of the following is NOT an example of how configuration management supports testing?",
            "options": [
                {
                    "key": "a",
                    "text": "All commits to the repository are uniquely identified and version controlled"
                },
                {
                    "key": "b",
                    "text": "All changes in the test environment elements are tracked"
                },
                {
                    "key": "c",
                    "text": "All requirement specifications are referenced unambiguously in test plans"
                },
                {
                    "key": "d",
                    "text": "All identified defects have an assigned status"
                }
            ],
            "correctAnswer": "d",
            "selectType": "single",
            "explanation": {
                "a": "When a user reports a software failure, thanks to the unique identification of commits, it is possible to reassemble the files from the software version which was used by the user (as well as the corresponding versions of the test scripts) and thus reproduce the failure and locate the defect faster",
                "b": "If a change to the test environment causes unexpected issues during testing, configuration management allows testers to roll back to a previous version of the environment. This ensures that testing can continue without being affected by the change",
                "c": "Configuration management ensures that all identified documentation (e.g., requirement specifications) and software items are referenced unambiguously in test documentation (e.g., test plans)",
                "d": "This is ensured by defect management, not by the configuration management process"
            },
            "learningObjective": "FL-5.4.1",
            "kLevel": "K2",
            "points": 1
        },
        {
            "id": 38,
            "questionText": "Consider the following defect report for a web-based shopping application: Application: WebShop v0.99 Defect: Login button not working Steps to Reproduce: Launch the website Click on the login button Expected result: The user should be redirected to the login page. Actual result: The login button does not respond when clicked. Severity: High Priority: Urgent What is the MOST important information that is missing from this defect report?",
            "options": [
                {
                    "key": "a",
                    "text": "Name of the tester and date"
                },
                {
                    "key": "b",
                    "text": "Test environment elements and their version numbers"
                },
                {
                    "key": "c",
                    "text": "Identification of the test object"
                },
                {
                    "key": "d",
                    "text": "Impact on the interests of stakeholders"
                }
            ],
            "correctAnswer": "b",
            "selectType": "single",
            "explanation": {
                "a": "This is important, but not as important as test environment elements",
                "b": "The important thing that is missing is the identification of the browser and device used for the testing. The browser and device information are important because such a defect can be browser- or device-specific. For example, a login button may work fine on one browser (or one version of a specific browser) but not on another. Therefore, the browser and device information can help the developers to reproduce the issue and find the root cause of the problem more quickly",
                "c": "The test object is identified (WebShop v0.99)",
                "d": "The impact is included – this is severity (high)"
            },
            "learningObjective": "FL-5.5.1",
            "kLevel": "K3",
            "points": 1
        },
        {
            "id": 39,
            "questionText": "Tools from which of the following categories help with the organization of test cases, detected defects and configuration management?",
            "options": [
                {
                    "key": "a",
                    "text": "Test execution and coverage tools"
                },
                {
                    "key": "b",
                    "text": "Test design and implementation tools"
                },
                {
                    "key": "c",
                    "text": "Defect management tools"
                },
                {
                    "key": "d",
                    "text": "Test management tools"
                }
            ],
            "correctAnswer": "d",
            "selectType": "single",
            "explanation": {
                "a": "Test execution and coverage tools facilitate the automated execution of test cases and the measurement of the coverage achieved by running those test cases. However, these tools do not help with the organization of defects and configuration management",
                "b": "Test design and test implementation tools facilitate the generation of test cases, test data and test procedures, but they do not help with the organization of defects and configuration management",
                "c": "Defect management tools are used to manage defects but are not testing tools and are not used to organize test cases or configuration management",
                "d": "Test management tools increase the test process efficiency by facilitating the management of the software development lifecycle (SDLC), requirements, tests, defects, and configuration management"
            },
            "learningObjective": "FL-6.1.1",
            "kLevel": "K2",
            "points": 1
        },
        {
            "id": 40,
            "questionText": "Which of the following is MOST likely to be a benefit of test automation?",
            "options": [
                {
                    "key": "a",
                    "text": "The capability of generating test cases without access to the test basis"
                },
                {
                    "key": "b",
                    "text": "The achievement of increased coverage through more objective assessment"
                },
                {
                    "key": "c",
                    "text": "The increase in test execution times available with higher processing power"
                },
                {
                    "key": "d",
                    "text": "The prevention of human errors through greater consistency and repeatability"
                }
            ],
            "correctAnswer": "d",
            "selectType": "single",
            "explanation": {
                "a": "'The capability of generating test cases without access to the test basis' is not possible. The generation of test cases by either testers or tools requires access to the test basis",
                "b": "'The achievement of increased coverage through more objective assessment' is not a direct benefit of test automation. Test automation will provide more objective assessment of coverage, however that objective assessment will not increase the coverage. Only by using the results of the coverage to write further test cases can the coverage possibly be increased",
                "c": "'The increase in test execution times available with higher processing power' is a contradictory statement as higher processing power would normally reduce execution times, and increased execution times are not a benefit as the testing would take longer",
                "d": "The prevention of human errors through greater consistency and repeatability is a benefit of test automation as test automation cannot suffer from human errors. For instance, it means that tests are consistently derived from requirements, test data is created in a systematic manner, and tests are executed by a tool in the same order with the same frequency"
            },
            "learningObjective": "FL-6.2.1",
            "kLevel": "K1",
            "points": 1
        }
    ]
}